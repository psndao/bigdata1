# MapReduce â€“ most_frequent

Ce projet implÃ©mente un job MapReduce en Python avec Hadoop Streaming pour identifier **le mot le plus frÃ©quent** dans un corpus texte.

## ðŸ“Œ Objectif

- Compter les mots d'un fichier texte (Word Count)
- Trouver le mot le plus frÃ©quent parmi ces mots

## ðŸ›  Technologies utilisÃ©es

- Hadoop HDFS
- Hadoop Streaming
- Python 3
- Cluster Big Data Adaltas

## ðŸ—‚ Structure du projet


## ðŸš€ Ã‰tapes de rÃ©alisation

### 1. Word Count (TP 1)

```bash
mapred streaming -D mapreduce.job.reduces=2 \
  -files word_count/mapper.py,word_count/reducer.py \
  -input /education/$GROUP/resources/lab3/mapred-input \
  -output /education/$GROUP/$USER/lab3/word-count \
  -mapper "python3 mapper.py" -reducer "python3 reducer.py"


mapred streaming -D stream.non.zero.exit.is.failure=false \
  -files most_frequent_mapper.py,most_frequent_reducer.py \
  -input /education/$GROUP/$USER/lab3/word-count \
  -output /education/$GROUP/$USER/lab3/most-frequent \
  -mapper "python3 most_frequent_mapper.py" -reducer "python3 most_frequent_reducer.py"



hdfs dfs -cat /education/$GROUP/$USER/lab3/most-frequent/part-*
# RÃ©sultat : the    13604
